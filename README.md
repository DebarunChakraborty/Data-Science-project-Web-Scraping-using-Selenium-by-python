# Data-Science-project-Web-Scraping-using-Selenium-by-python
In this project I intend to develop a python script to be use as an automatic web scraper of any google search result. It is an interesting project and most importantly very common application in the field of data science. 

LETS START!

So what is Web Srcaping?

Web scraping refers to the extraction of data from a website. This information is collected and then exported into a format that is more useful for the user. 
Be it a spreadsheet or an API[1].

For more details please Visit(https://www.parsehub.com/blog/what-is-web-scraping/)

Objectives of this Project:

1. To extract some specific information of first 10 pages ( pages may increase-depnds on the user) such as URL, title, page no., and the describtion of the search result using google Chrome.   
3. Create a csv. file to store all the result generated.


Requiredments:
1. selenium
2. Resepective Chrome driver compatible to your chrome version. Which can be downloaded from (https://chromedriver.chromium.org/downloads)
3. Pandas

Important Point:

This repository content a Jupyter notebook named "Web_Scrapping_Task", a readme file, a chromedriver of version 106 and output .csv file.



Reference:

[1] Martin Perez, What is Web Scraping and What is it Used For? https://www.parsehub.com/blog/what-is-web-scraping/
